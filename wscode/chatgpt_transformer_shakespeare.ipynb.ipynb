{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7acdd43-2b92-49bc-a9e9-da4f3058614b",
   "metadata": {},
   "source": [
    "# chatgpt_transformer_shakespeare.ipynb\n",
    "# WESmith 06/22/23\n",
    "## experiment with chatgpt source code in writing a transformer to generate text\n",
    "## status: this not finished: will need to add a batch mode and run on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c01b78b-8c3d-4ee1-a84a-5ddf724b0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import string\n",
    "import random\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3471030c-8b21-41d0-b3df-c5d4ce7cc2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85eb8d0-ecba-4563-8722-85b759777523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "input_size = len(string.ascii_letters) + len(string.punctuation) + 1\n",
    "hidden_size = 128\n",
    "output_size = input_size\n",
    "num_layers = 4\n",
    "num_heads = 8\n",
    "dropout = 0.1\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0471f-854d-4d54-a24c-03c8e0bcb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Shakespeare text\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6b15a-7520-4bb5-a805-4c6dad6b0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(all_characters)\n",
    "vocab_size, len(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43780d25-df36-42fa-b818-2ac2901e2ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join([c for c in all_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e034ef-1fb7-4dc4-ab93-c39dd3a4eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7a02e-d792-46e9-9493-43b5730c5728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data (Shakespeare text)\n",
    "#shakespeare_text = \"YOUR_SHAKESPEARE_TEXT_HERE\"\n",
    "#all_characters = string.ascii_letters + string.punctuation + ' '\n",
    "char_to_idx = {char: i for i, char in enumerate(all_characters)}\n",
    "idx_to_char = {i: char for i, char in enumerate(all_characters)}\n",
    "\n",
    "# Convert the text to a tensor\n",
    "full_text_tensor = torch.tensor([[char_to_idx[char] for char in shakespeare_text]], \n",
    "                           dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17fe6d-417a-4ed6-81bf-ca8561b0a260",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391e1cbf-5d8d-4017-b36b-edfe07e1504e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_text_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# batches not used in initial chatgpt result, limit number of text chars and run as one batch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m----> 3\u001b[0m text_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mfull_text_tensor\u001b[49m[\u001b[38;5;241m0\u001b[39m, :limit]\n\u001b[1;32m      4\u001b[0m text_tensor \u001b[38;5;241m=\u001b[39m text_tensor\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m text_tensor\u001b[38;5;241m.\u001b[39mshape, full_text_tensor\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_text_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "# batches not used in initial chatgpt result, limit number of text chars and run as one batch\n",
    "limit = 1000\n",
    "text_tensor = full_text_tensor[0, :limit]\n",
    "text_tensor = text_tensor.unsqueeze(0)\n",
    "text_tensor.shape, full_text_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917afa39-59b4-4b7a-bff4-4fe3dd98a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a sample of text from the generator model\n",
    "def generate_sample(start_char='A', length=100):\n",
    "    with torch.no_grad():\n",
    "        input_chars = torch.tensor([[char_to_idx[start_char]]], dtype=torch.long).to(device)\n",
    "\n",
    "        generated_text = start_char\n",
    "\n",
    "        for _ in range(length):\n",
    "            output = generator(input_chars)\n",
    "            _, top_char_idx = output[:, -1, :].topk(1)\n",
    "            generated_char = idx_to_char[top_char_idx.item()]\n",
    "\n",
    "            generated_text += generated_char\n",
    "\n",
    "            input_chars = torch.cat((input_chars, top_char_idx.unsqueeze(0)), dim=1)\n",
    "\n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabce0d-dabc-4757-b49c-e7facba24b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator model using Transformer architecture\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads, dropout):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding   = nn.Embedding(input_size, hidden_size)\n",
    "        self.transformer = nn.Transformer(d_model=hidden_size, nhead=num_heads, \n",
    "                                          num_encoder_layers=num_layers, \n",
    "                                          num_decoder_layers=num_layers, \n",
    "                                          dim_feedforward=hidden_size, dropout=dropout)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input_chars):\n",
    "        input_embedded = self.embedding(input_chars)\n",
    "        input_embedded = input_embedded.permute(1, 0, 2)  # Reshape for Transformer input\n",
    "\n",
    "        output = self.transformer(input_embedded, input_embedded)\n",
    "        output = self.softmax(self.out(output))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693fec1-dfb0-4734-a189-0f3b61501135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the generator model\n",
    "generator = Generator(input_size, hidden_size, output_size, \n",
    "                      num_layers, num_heads, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40e17c-144c-416e-8f00-b473bb2c3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WS added to see model size\n",
    "num = sum(p.numel() for p in generator.parameters())\n",
    "print(f'The model has {num:.5g} parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd91b79-a131-4939-aae5-5e0e6758cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(generator.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88e63d-3609-4546-8f6b-a7ed26f82f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28aa90-8285-48fa-bb4c-b05f39ee91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the generator model\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 0\n",
    "    generator.zero_grad()\n",
    "\n",
    "    output = generator(text_tensor[:, :-1])\n",
    "    target = text_tensor[:, 1:]\n",
    "    loss = criterion(output.view(-1, output_size), target.view(-1))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5b76a-e405-4060-9c5b-73d7ddb1e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sample of Shakespeare-like text\n",
    "sample_text = generate_sample(start_char='A', length=200)\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78501844-3474-48d8-bd88-e720e5e3bff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
